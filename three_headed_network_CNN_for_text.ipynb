{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13pL--6rycN3"
   },
   "source": [
    "## Homework02: Three headed network in PyTorch\n",
    "\n",
    "This notebook accompanies the [week02](https://github.com/girafe-ai/natural-language-processing/tree/master/week02_cnn_for_texts) practice session. Refer to that notebook for more comments.\n",
    "\n",
    "All the preprocessing is the same as in the classwork. *Including the data leakage in the train test split (it's still for bonus points).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8zS7m-gycN5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already downloaded the data on the Seminar, simply run through the next cells. Otherwise uncomment the next cell (and comment the another one ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    17    0    17    0     0     44      0 --:--:-- --:--:-- --:--:--    44\n",
      "100   342  100   342    0     0    485      0 --:--:-- --:--:-- --:--:--   485\n",
      "100  119M  100  119M    0     0  5250k      0  0:00:23  0:00:22  0:00:01 5908k  0:00:23 --:--:-- 6397k\n",
      "x Train_rev1.csv\n",
      "--2023-05-14 22:02:22--  https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22f_msai/homeworks/assignment02_three_headed_network/network.py\n",
      "Распознаётся raw.githubusercontent.com (raw.githubusercontent.com)… 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Подключение к raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 1469 (1,4K) [text/plain]\n",
      "Сохранение в: «network.py.3»\n",
      "\n",
      "network.py.3        100%[===================>]   1,43K  --.-KB/s    за 0s      \n",
      "\n",
      "2023-05-14 22:02:23 (15,7 MB/s) - «network.py.3» сохранён [1469/1469]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# uncomment and run this cell, if you don't have data locally yet.\n",
    "\n",
    "!curl -L \"https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1\" -o Train_rev1.csv.tar.gz\n",
    "!tar -xvzf ./Train_rev1.csv.tar.gz\n",
    "\n",
    "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
    "\n",
    "!wget https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22f_msai/homeworks/assignment02_three_headed_network/network.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "vwN72gd4ycOA",
    "outputId": "7b9e8549-3128-4041-c4be-33fb6f326c78"
   },
   "outputs": [],
   "source": [
    "# run this cell if you have downloaded the dataset on the seminar\n",
    "#data = pd.read_csv(\"../../week02_CNN_n_Vanishing_gradient/Train_rev1.csv\", index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "UuuKIKfrycOH",
    "outputId": "e5de0f94-a4f6-4b51-db80-9d11ddc1db31"
   },
   "outputs": [],
   "source": [
    "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
    "text_columns = [\"Title\", \"FullDescription\"]\n",
    "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
    "target_column = \"Log1pSalary\"\n",
    "\n",
    "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
    "\n",
    "data.sample(3)\n",
    "\n",
    "data_for_autotest = data[-5000:]\n",
    "data = data[:-5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RUWkpd7PycOQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized:\n",
      "2         mathematical modeller / simulation analyst / o...\n",
      "100002    a successful and high achieving specialist sch...\n",
      "200002    web designer html , css , javascript , photosh...\n",
      "Name: FullDescription, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239768it [00:12, 18737.30it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "# see task above\n",
    "def normalize(text):\n",
    "    text = str(text).lower()\n",
    "    return ' '.join(tokenizer.tokenize(text))\n",
    "    \n",
    "data[text_columns] = data[text_columns].applymap(normalize)\n",
    "\n",
    "print(\"Tokenized:\")\n",
    "print(data[\"FullDescription\"][2::100000])\n",
    "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
    "assert data[\"Title\"][54321] == 'international digital account manager ( german )'\n",
    "\n",
    "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
    "# build a dictionary { token -> it's count }\n",
    "from collections import Counter\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "token_counts = Counter()# <YOUR CODE HERE>\n",
    "for _, row in tqdm(data[text_columns].iterrows()):\n",
    "    for string in row:\n",
    "        token_counts.update(string.split())\n",
    "\n",
    "# hint: you may or may not want to use collections.Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2598827"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counts.most_common(1)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "GiOWbc15ycOb",
    "outputId": "1e807140-5513-4af0-d9a9-9f029059a553"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tokens : 201127\n",
      "('and', 2598827)\n",
      "('.', 2471477)\n",
      "(',', 2266256)\n",
      "('the', 2036428)\n",
      "('to', 1977039)\n",
      "...\n",
      "('dbms_stats', 1)\n",
      "('dbms_output', 1)\n",
      "('dbms_job', 1)\n",
      "Correct!\n",
      "Vocabulary size: 33795\n",
      "Correct!\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique tokens :\", len(token_counts))\n",
    "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
    "print('...')\n",
    "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
    "\n",
    "assert token_counts.most_common(1)[0][1] in  range(2500000, 2700000)\n",
    "assert len(token_counts) in range(199000, 210000)\n",
    "print('Correct!')\n",
    "\n",
    "min_count = 10\n",
    "\n",
    "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
    "tokens = [token for token, count in token_counts.items() if count >= min_count]# <YOUR CODE HERE>\n",
    "# Add a special tokens for unknown and empty words\n",
    "UNK, PAD = \"UNK\", \"PAD\"\n",
    "tokens = [UNK, PAD] + sorted(tokens)\n",
    "print(\"Vocabulary size:\", len(tokens))\n",
    "\n",
    "assert type(tokens) == list\n",
    "assert len(tokens) in range(32000, 35000)\n",
    "assert 'me' in tokens\n",
    "assert UNK in tokens\n",
    "print(\"Correct!\")\n",
    "\n",
    "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
    "assert isinstance(token_to_id, dict)\n",
    "assert len(token_to_id) == len(tokens)\n",
    "for tok in tokens:\n",
    "    assert tokens[token_to_id[tok]] == tok\n",
    "\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JEsLeBjVycOw"
   },
   "outputs": [],
   "source": [
    "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
    "\n",
    "def as_matrix(sequences, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "        \n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "    \n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "JiBlPkdKycOy",
    "outputId": "3866b444-1e2d-4d79-d429-fecc6d8e02a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines:\n",
      "engineering systems analyst\n",
      "hr assistant\n",
      "senior ec & i engineer\n",
      "\n",
      "Matrix:\n",
      "[[10705 29830  2143     1     1]\n",
      " [14875  2817     1     1     1]\n",
      " [27345 10107    15 15069 10702]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lines:\")\n",
    "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
    "print(\"Matrix:\")\n",
    "print(as_matrix(data[\"Title\"][::100000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "DpOlBp7ZycO6",
    "outputId": "30a911f2-7d35-4cb5-8991-60457b1e8bac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DictVectorizer</label><div class=\"sk-toggleable__content\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float32'>, sparse=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# we only consider top-1k most frequent companies to minimize memory usage\n",
    "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
    "recognized_companies = set(top_companies)\n",
    "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
    "\n",
    "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
    "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yk4jmtAYycO8"
   },
   "source": [
    "### The deep learning part\n",
    "\n",
    "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
    "\n",
    "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
    "\n",
    "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes.\n",
    "\n",
    "\n",
    "#### Here comes the simple one-headed network from the seminar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "TngLcWA0ycO_",
    "outputId": "6731b28c-07b1-41dc-9574-f76b01785bba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  191814\n",
      "Validation size =  47954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "data_train.index = range(len(data_train))\n",
    "data_val.index = range(len(data_val))\n",
    "\n",
    "print(\"Train size = \", len(data_train))\n",
    "print(\"Validation size = \", len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2PXuKgOSycPB"
   },
   "outputs": [],
   "source": [
    "def make_batch(data, max_len=None, word_dropout=0):\n",
    "    \"\"\"\n",
    "    Creates a keras-friendly dict from the batch data.\n",
    "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
    "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
    "    \"\"\"\n",
    "    batch = {}\n",
    "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
    "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
    "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
    "    \n",
    "    if word_dropout != 0:\n",
    "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
    "    \n",
    "    if target_column in data.columns:\n",
    "        batch[target_column] = data[target_column].values\n",
    "    \n",
    "    return batch\n",
    "\n",
    "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
    "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
    "    dropout_mask &= matrix != pad_ix\n",
    "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "I6LpEQf0ycPD",
    "outputId": "e3520cae-fba1-46cc-a216-56287b6e4929"
   },
   "outputs": [],
   "source": [
    "a = make_batch(data_train[:3], max_len=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But to start with let's build the simple model using only the part of the data. Let's create the baseline solution using only the description part (so it should definetely fit into the Sequential model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will need these to make it simple\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class Reorder(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.permute((0, 2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate minibatches we will use simple pyton generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
    "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
    "    while True:\n",
    "        indices = np.arange(len(data))\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(indices)\n",
    "\n",
    "        for start in range(0, len(indices), batch_size):\n",
    "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
    "            target = batch.pop(target_column)\n",
    "            yield batch, target\n",
    "        \n",
    "        if not cycle: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iterate_minibatches(data_train, 3)\n",
    "batch, target = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is some startup code:\n",
    "n_tokens=len(tokens)\n",
    "n_cat_features=len(categorical_vectorizer.vocabulary_)\n",
    "hid_size=64\n",
    "simple_model = nn.Sequential()\n",
    "\n",
    "simple_model.add_module('emb', nn.Embedding(num_embeddings=n_tokens, embedding_dim=hid_size))\n",
    "simple_model.add_module('reorder', Reorder())\n",
    "simple_model.add_module('conv1', nn.Conv1d(\n",
    "    in_channels=hid_size,\n",
    "    out_channels=hid_size,\n",
    "    kernel_size=2)\n",
    "                       )\n",
    "simple_model.add_module('relu1', nn.ReLU())\n",
    "simple_model.add_module('adapt_avg_pool', nn.AdaptiveAvgPool1d(output_size=1))\n",
    "simple_model.add_module('flatten1', Flatten())\n",
    "simple_model.add_module('linear1', nn.Linear(in_features=hid_size, out_features=1))\n",
    "# <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': array([[ 6480, 18776, 30145,     1,     1,     1,     1,     1],\n",
       "        [10720, 30069, 27147, 26977,  4030, 32907, 19559, 22755],\n",
       "        [27345, 16380, 28518, 18842, 25754,  7252,     1,     1]],\n",
       "       dtype=int32),\n",
       " 'FullDescription': array([[ 2545, 33635,   965, ...,     1,     1,     1],\n",
       "        [ 2545, 33635,   965, ...,  2386, 32637, 31804],\n",
       "        [ 9888, 30762,  4938, ...,     1,     1,     1]], dtype=int32),\n",
       " 'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remember!__ We are working with regression problem and predicting only one number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0309],\n",
       "        [0.0502],\n",
       "        [0.0234]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try this to check your model. `torch.long` tensors are required for nn.Embedding layers.\n",
    "simple_model(torch.tensor(batch['FullDescription'], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 595)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['FullDescription'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now simple training pipeline (it's commented because we've already done that in class. No need to do it again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import clear_output\n",
    "# from random import sample\n",
    "\n",
    "# epochs = 1\n",
    "\n",
    "# model = simple_model\n",
    "# opt = torch.optim.Adam(model.parameters())\n",
    "# loss_func = nn.MSELoss()\n",
    "\n",
    "# history = []\n",
    "# for epoch_num in range(epochs):\n",
    "#     for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
    "#         # Preprocessing the batch data and target\n",
    "#         batch = torch.tensor(batch['FullDescription'], dtype=torch.long)\n",
    "\n",
    "#         target = torch.tensor(target)\n",
    "\n",
    "\n",
    "#         predictions = model(batch)\n",
    "#         predictions = predictions.view(predictions.size(0))\n",
    "\n",
    "#         loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
    "\n",
    "#         # train with backprop\n",
    "#         loss.backward()\n",
    "#         opt.step()\n",
    "#         opt.zero_grad()\n",
    "#         # <YOUR CODE HERE>\n",
    "\n",
    "#         history.append(loss.data.numpy())\n",
    "#         if (idx+1)%10==0:\n",
    "#             clear_output(True)\n",
    "#             plt.plot(history,label='loss')\n",
    "#             plt.legend()\n",
    "#             plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual homework starts here\n",
    "__Your ultimate task is to code the three headed network described on the picture below.__ \n",
    "To make it closer to the real world, please store the network code in file `network.py` in this directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0eI5h9UMycPF"
   },
   "source": [
    "#### Architecture\n",
    "\n",
    "Our main model consists of three branches:\n",
    "* Title encoder\n",
    "* Description encoder\n",
    "* Categorical features encoder\n",
    "\n",
    "We will then feed all 3 branches into one common network that predicts salary.\n",
    "\n",
    "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>\n",
    "\n",
    "This clearly doesn't fit into PyTorch __Sequential__ interface. To build such a network, one will have to use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "\n",
    "class ThreeInputsNet(nn.Module):\n",
    "    def __init__(self, n_tokens, n_cat_features, concat_number_of_features, hid_size=64):\n",
    "        super(ThreeInputsNet, self).__init__()\n",
    "        self.title_emb = nn.Embedding(n_tokens, embedding_dim=hid_size)\n",
    "        self.title_conv = nn.Sequential(\n",
    "          nn.Conv1d(in_channels=hid_size, out_channels=hid_size, kernel_size=2),\n",
    "          nn.ReLU(),\n",
    "          nn.AdaptiveAvgPool1d(output_size=1),\n",
    "          Flatten()\n",
    "        )\n",
    "        \n",
    "        self.full_emb = nn.Embedding(n_tokens, embedding_dim=hid_size)\n",
    "        self.full_conv = nn.Sequential(\n",
    "          nn.Conv1d(in_channels=hid_size, out_channels=hid_size, kernel_size=2),\n",
    "          nn.ReLU(),\n",
    "          nn.AdaptiveAvgPool1d(output_size=1),\n",
    "          Flatten()\n",
    "        )\n",
    "        \n",
    "        self.category_out = nn.Sequential(\n",
    "          nn.Linear(n_cat_features, 2*hid_size),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(2*hid_size, hid_size),\n",
    "        )\n",
    "\n",
    "\n",
    "        # Example for the final layers (after the concatenation)\n",
    "        self.inter_dense = nn.Linear(in_features=concat_number_of_features, out_features=hid_size*2)\n",
    "        self.final_dense = nn.Linear(in_features=hid_size*2, out_features=1)\n",
    "        \n",
    "\n",
    "    def forward(self, whole_input):\n",
    "        input1, input2, input3 = whole_input\n",
    "        title = self.title_emb(input1).permute((0, 2, 1))\n",
    "        title = self.title_conv(title)\n",
    "        \n",
    "        full = self.full_emb(input2).permute((0, 2, 1))\n",
    "        full = self.full_conv(full)     \n",
    "        \n",
    "        category = self.category_out(input3)      \n",
    "        \n",
    "        concatenated = torch.cat(\n",
    "            [\n",
    "            title.view(title.size(0), -1),\n",
    "            full.view(full.size(0), -1),\n",
    "            category.view(category.size(0), -1)\n",
    "            ],\n",
    "            dim=1)\n",
    "        \n",
    "        out = self.inter_dense(concatenated)\n",
    "        out = nn.ReLU()(out)\n",
    "        out = self.final_dense(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0231],\n",
       "        [-0.0505],\n",
       "        [-0.0493]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_output_shape(model, input_shape, iscontact = False):\n",
    "    if not iscontact:\n",
    "        dummy_input = torch.ones(*input_shape, dtype=torch.long)\n",
    "    else :\n",
    "        dummy_input = torch.ones(*input_shape)\n",
    "        \n",
    "    output_shape = model(dummy_input).shape\n",
    "    return output_shape\n",
    "\n",
    "# initialize the model\n",
    "model = ThreeInputsNet(\n",
    "    n_tokens=len(tokens),\n",
    "    n_cat_features=len(categorical_vectorizer.vocabulary_),\n",
    "    concat_number_of_features=192\n",
    ")\n",
    "\n",
    "\n",
    "testing_batch, _ = next(iterate_minibatches(data_train, 3))\n",
    "testing_batch = [\n",
    "    torch.tensor(testing_batch['Title'], dtype=torch.long),\n",
    "    torch.tensor(testing_batch['FullDescription'], dtype=torch.long),\n",
    "    torch.tensor(testing_batch['Categorical'])\n",
    "]\n",
    "model(testing_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems fine!\n"
     ]
    }
   ],
   "source": [
    "assert model(testing_batch).shape == torch.Size([3, 1])\n",
    "assert model(testing_batch).dtype == torch.float32\n",
    "print('Seems fine!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the network for a while (100 batches would be fine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training pipeline comes here (almost the same as for the simple_model)\n",
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "history = []\n",
    "for epoch_num in range(epochs):\n",
    "    for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
    "        # Preprocessing the batch data and target\n",
    "\n",
    "        batch = [\n",
    "            torch.tensor(batch['Title'], dtype=torch.long),\n",
    "            torch.tensor(batch['FullDescription'], dtype=torch.long),\n",
    "            torch.tensor(batch['Categorical'])\n",
    "            ]\n",
    "\n",
    "        target = torch.tensor(target)\n",
    "\n",
    "\n",
    "        predictions = model(batch)\n",
    "        predictions = predictions.view(predictions.size(0))\n",
    "\n",
    "        loss = loss_func(predictions, target)\n",
    "\n",
    "        # train with backprop\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        history.append(loss.data.numpy())\n",
    "        if (idx+1)%10==0:\n",
    "            clear_output(True)\n",
    "            plt.plot(history,label='loss')\n",
    "            plt.legend()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to evaluate the model it can be switched to `eval` state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreeInputsNet(\n",
       "  (title_emb): Embedding(33795, 64)\n",
       "  (title_conv): Sequential(\n",
       "    (0): Conv1d(64, 64, kernel_size=(2,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): AdaptiveAvgPool1d(output_size=1)\n",
       "    (3): Flatten()\n",
       "  )\n",
       "  (full_emb): Embedding(33795, 64)\n",
       "  (full_conv): Sequential(\n",
       "    (0): Conv1d(64, 64, kernel_size=(2,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): AdaptiveAvgPool1d(output_size=1)\n",
       "    (3): Flatten()\n",
       "  )\n",
       "  (category_out): Sequential(\n",
       "    (0): Linear(in_features=3746, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  )\n",
       "  (inter_dense): Linear(in_features=192, out_features=128, bias=True)\n",
       "  (final_dense): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(model, data, batch_size=256, name=\"\", three_inputs_mode=True, **kw):\n",
    "    squared_error = abs_error = num_samples = 0.0\n",
    "    output_list = []\n",
    "    for batch_x, batch_y in tqdm.tqdm(iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw)):\n",
    "        if three_inputs_mode:\n",
    "            batch = [\n",
    "                torch.tensor(batch_x['Title'], dtype=torch.long),\n",
    "                torch.tensor(batch_x['FullDescription'], dtype=torch.long),\n",
    "                torch.tensor(batch_x['Categorical'])\n",
    "            ]\n",
    "        else:\n",
    "            batch = torch.tensor(batch_x['FullDescription'], dtype=torch.long)\n",
    "\n",
    "        batch_pred = model(batch)[:, 0].detach().numpy()\n",
    "        \n",
    "        output_list.append((list(batch_pred), list(batch_y)))\n",
    "        \n",
    "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
    "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
    "        num_samples += len(batch_y)\n",
    "    print(\"%s results:\" % (name or \"\"))\n",
    "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
    "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
    "    \n",
    "\n",
    "    batch_pred = [c for x in output_list for c in x[0]]\n",
    "    batch_y = [c for x in output_list for c in x[1]]\n",
    "    output_df = pd.DataFrame(list(zip(batch_pred, batch_y)), columns=['batch_pred', 'batch_y'])\n",
    "    output_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:02,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission results:\n",
      "Mean square error: 0.13873\n",
      "Mean absolute error: 0.28831\n",
      "Submission file generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_submission(model, data_for_autotest, name='Submission')\n",
    "print('Submission file generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Both the notebook and the `.py` file are required to submit this homework.__"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CNN_for_texts.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
